{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy TrainingDataTotal and LabelDataTotal to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "input_dir = 'D:\\Data\\CNNTrainingCrop64_Added'\n",
    "train_data_total = glob(os.path.join(input_dir, 'TrainingDataTotal', '*'))\n",
    "label_data_total = glob(os.path.join(input_dir, 'LabelDataTotal', '*'))\n",
    "\n",
    "output_dir = 'D:\\DeepLearn\\input'\n",
    "output_dir_train = os.path.join(output_dir, 'TrainingDataTotal')\n",
    "output_dir_label = os.path.join(output_dir, 'LabelDataTotal')\n",
    "\n",
    "for train in train_data_total:\n",
    "    fname = train.split('\\\\')[-1]\n",
    "    shutil.copyfile(train, os.path.join(output_dir_train, fname))\n",
    "    \n",
    "for label in label_data_total:\n",
    "    fname = label.split('\\\\')[-1]\n",
    "    shutil.copyfile(label, os.path.join(output_dir_label, fname))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unqualified images based on QCToExclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "x = loadmat(os.path.join(input_dir, 'QCToExclude.mat'))\n",
    "exclude_array = x['exclude_array']\n",
    "\n",
    "flat_array = [item for sublist in exclude_array for item in sublist]\n",
    "numToExclude = sum(flat_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.tif\n",
      "137.tif\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "train_glob = glob(os.path.join(output_dir_train, '*'))\n",
    "fnames = [train.split('\\\\')[-1] for train in train_glob]\n",
    "flat_array = [item for sublist in exclude_array for item in sublist]\n",
    "ex_list = []\n",
    "for i, e in enumerate(flat_array):\n",
    "    if e == 1:\n",
    "        print(fnames[i])\n",
    "        ex_list.append(fnames[i])\n",
    "        \n",
    "for ex in ex_list:\n",
    "    fnames.remove(ex)\n",
    "    \n",
    "if len(fnames)%5 != 0:\n",
    "    fnum = int(np.ceil(len(fnames)/5) * 5)\n",
    "else:\n",
    "    fnum = len(fnames)\n",
    "\n",
    "\n",
    "training_data = random.sample(fnames, int(fnum*0.8))\n",
    "training_set = set(training_data)\n",
    "total_set = set(fnames)\n",
    "testing_set = total_set - training_set\n",
    "testing_data = list(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data to each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train in training_data:\n",
    "    shutil.copyfile(os.path.join(os.path.join(output_dir, 'TrainingDataTotal', train)), os.path.join(output_dir, 'TrainingData',train))\n",
    "    shutil.copyfile(os.path.join(os.path.join(output_dir, 'LabelDataTotal', train)), os.path.join(output_dir, 'TrainingLabel',train))\n",
    "    \n",
    "for test in testing_data:\n",
    "    shutil.copyfile(os.path.join(os.path.join(output_dir, 'TrainingDataTotal', test)), os.path.join(output_dir, 'TestingData',test))\n",
    "    shutil.copyfile(os.path.join(os.path.join(output_dir, 'LabelDataTotal', test)), os.path.join(output_dir, 'TestingLabel',test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05/23/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select images from D:\\DeepLearn\\input\\LabelDataTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "base_dir = 'D:\\DeepLearn\\input'\n",
    "label_dir = os.path.join(base_dir, 'LabelDataTotal')\n",
    "\n",
    "labels = glob(os.path.join(label_dir, '*'))\n",
    "nonzero_labels = []\n",
    "for l in labels:\n",
    "    img =  np.array(Image.open(l))\n",
    "    if np.sum(img) > 255 * 10:\n",
    "        nonzero_labels.append(l)\n",
    "\n",
    "output_dir = 'D:\\DeepLearn\\input'\n",
    "output_dir_label = os.path.join(output_dir, 'LabelDataTotal_BigInfarct')\n",
    "output_dir_train = os.path.join(output_dir, 'TrainingDataTotal_BigInfarct')\n",
    "train_dir = os.path.join(base_dir, 'TrainingDataTotal')\n",
    "\n",
    "if not os.path.isdir(output_dir_label):\n",
    "    os.mkdir(output_dir_label)\n",
    "\n",
    "if not os.path.isdir(output_dir_train):\n",
    "    os.mkdir(output_dir_train)\n",
    "    \n",
    "for nz_label in nonzero_labels:\n",
    "    fname = nz_label.split('\\\\')[-1]\n",
    "    shutil.copyfile(nz_label, os.path.join(output_dir_label, fname))\n",
    "    shutil.copyfile(os.path.join(train_dir, fname), os.path.join(output_dir_train, fname))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickup = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,27,28,29,30,33,34,35,36,41,42,43,44,47,48,49,50,51,52,53,54,55,56,57,58,59,60,62,63,64,\n",
    "65,66,70,71,72,75,96,97,98,132,133,134,135,138,139,140,141,150,151,152,153,154,168,169,170,171,172,181,182,183,184,226,227,\n",
    "228,229,230,234,235,236,237,238,239,286,287,288,289,290,293,294,295,296,297,301,302,303,304,305,325,326,327,331,367,368,369,370,\n",
    "371,372,373,431,432,433,434,435,442,444,445,446,448,451,452,453,454,455,470,471,472,473,474,481,482,483,524,525,526,\n",
    "527,529,530,531,550,551,552]\n",
    "magna = [18,19,20,21,190,191,192,193,194,195,199,200,201,202,232,233,252,256,257,258,292,306,307,308,309,310,320,321,\n",
    "        360,361,362,363,364,365,377,378,379,380,412,413,430,466,467,476,477,478,479,480,496,497,498,522,523,532,533,534,\n",
    "        536]\n",
    "sel = sorted(pickup + magna)\n",
    "\n",
    "output_dir = 'D:\\DeepLearn\\input'\n",
    "output_dir_label = os.path.join(output_dir, 'LabelDataTotal_Select')\n",
    "output_dir_train = os.path.join(output_dir, 'TrainingDataTotal_Select')\n",
    "output_dir_mask = os.path.join(output_dir, 'MaskDataTotal_Select')\n",
    "train_dir = os.path.join(base_dir, 'TrainingDataTotal')\n",
    "label_dir = os.path.join(base_dir, 'LabelDataTotal')\n",
    "mask_dir = os.path.join(base_dir, 'MaskDataTotal')\n",
    "if not os.path.isdir(output_dir_label):\n",
    "    os.mkdir(output_dir_label)\n",
    "\n",
    "if not os.path.isdir(output_dir_train):\n",
    "    os.mkdir(output_dir_train)\n",
    "\n",
    "if not os.path.isdir(output_dir_mask):\n",
    "    os.mkdir(output_dir_mask)\n",
    "\n",
    "fnames = []\n",
    "for i in sel:\n",
    "    fname = str(i) + '.tif'\n",
    "    shutil.copyfile(os.path.join(train_dir, fname), os.path.join(output_dir_train, fname))\n",
    "    shutil.copyfile(os.path.join(label_dir, fname), os.path.join(output_dir_label, fname))\n",
    "    shutil.copyfile(os.path.join(mask_dir, fname), os.path.join(output_dir_mask, fname))\n",
    "    fnames.append(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "training_data = random.sample(fnames, 160)\n",
    "training_set = set(training_data)\n",
    "total_set = set(fnames)\n",
    "testing_set = total_set - training_set\n",
    "testing_data = list(testing_set)\n",
    "if not os.path.isdir(os.path.join(output_dir, 'TrainingData_Select')):\n",
    "    os.mkdir(os.path.join(output_dir, 'TrainingData_Select'))\n",
    "if not os.path.isdir(os.path.join(output_dir, 'TestingData_Select')):\n",
    "    os.mkdir(os.path.join(output_dir, 'TestingData_Select'))  \n",
    "    \n",
    "if not os.path.isdir(os.path.join(output_dir, 'TrainingLabel_Select')):\n",
    "    os.mkdir(os.path.join(output_dir, 'TrainingLabel_Select')) \n",
    "if not os.path.isdir(os.path.join(output_dir, 'TestingLabel_Select')):\n",
    "    os.mkdir(os.path.join(output_dir, 'TestingLabel_Select')) \n",
    "\n",
    "if not os.path.isdir(os.path.join(output_dir, 'TrainingMask_Select')):\n",
    "    os.mkdir(os.path.join(output_dir, 'TrainingMask_Select')) \n",
    "if not os.path.isdir(os.path.join(output_dir, 'TestingMask_Select')):\n",
    "    os.mkdir(os.path.join(output_dir, 'TestingMask_Select')) \n",
    "    \n",
    "for train in training_data:\n",
    "    shutil.copyfile(os.path.join(output_dir, 'TrainingDataTotal_Select', train), os.path.join(output_dir, 'TrainingData_Select',train))\n",
    "    shutil.copyfile(os.path.join(output_dir, 'LabelDataTotal_Select', train), os.path.join(output_dir, 'TrainingLabel_Select',train))\n",
    "    shutil.copyfile(os.path.join(output_dir, 'MaskDataTotal_Select', train), os.path.join(output_dir, 'TrainingMask_Select',train))\n",
    "\n",
    "for test in testing_data:\n",
    "    shutil.copyfile(os.path.join(output_dir, 'TrainingDataTotal_Select', test), os.path.join(output_dir, 'TestingData_Select',test))\n",
    "    shutil.copyfile(os.path.join(output_dir, 'LabelDataTotal_Select', test), os.path.join(output_dir, 'TestingLabel_Select',test))\n",
    "    shutil.copyfile(os.path.join(output_dir, 'MaskDataTotal_Select', test), os.path.join(output_dir, 'TestingMask_Select',test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[84,85,86,330,332,333,334,335,336,337,351,352,353,354,355,491,492,493,494,247,248,249,250,251]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
